{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "הפונקציה הראשית נמצאת בסוף הדף, נית לראות בה את סדר זימון הפעולות עם הסבר."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------סעיף 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#המרת קובץ EXCEL ל CSV\n",
    "def convert_excel_to_csv(input_file, output_file):\n",
    "    df = pd.read_excel(input_file, engine='openpyxl')  \n",
    "    df.to_csv(output_file, index=False, encoding='utf-8') \n",
    "\n",
    "#זימון הפונקציה\n",
    "# convert_excel_to_csv(\"logs.txt.xlsx\", \"logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#פונקציה המחלקת את הקובץ לחלקים קטנים יותר\n",
    "#הפונקציה משתמשת ב- chunksize כדי לחסוך בזיכרון.\n",
    "def split_csv_data(input_file, num_of_rows=100000, name_of_split_file=\"split_file_\"):\n",
    "    chunk_counter = 1\n",
    "\n",
    "    for chunk in pd.read_csv(input_file, chunksize=num_of_rows, encoding='utf-8'):\n",
    "        chunk.to_csv(f\"{name_of_split_file}{chunk_counter}.csv\", index=False, encoding=\"utf-8\")\n",
    "        chunk_counter += 1\n",
    "\n",
    "#     print(f\"הקובץ פוצל בהצלחה ל-{chunk_counter-1} חלקים!\")\n",
    "\n",
    "\n",
    "split_csv_data(\"logs.csv\", 100000, \"split\")\n",
    "\n",
    "# הכנסת כל המצביעים של הקבצים הקטנים לתוך מערך\n",
    "split_arr = glob.glob(\"split*.csv\") \n",
    "split_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#פונקציה המחשבת שכיחויות לכל חלק בנפרד.\n",
    "def count_errors_in_chunk(chunk_file, file_name):\n",
    "    error_counter = Counter()\n",
    "\n",
    "    with open(chunk_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            error_code = line.strip().split()[4]\n",
    "            error_code = error_code.replace('\"',\"\")\n",
    "            error_counter[error_code] += 1\n",
    "\n",
    "    output_file = f\"{file_name}_with_freq.csv\"\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Error_Code\", \"Count\"])\n",
    "        writer.writerows(error_counter.items())\n",
    "\n",
    "#     print(f\"שמירת התוצאה הסתיימה עבור {chunk_file} -> {output_file}\")\n",
    "#     print(f\"common {error_counter.most_common(1)}\")#כדי לראות את השגיאה השכיחה ביותר\n",
    "\n",
    "#זימון הפעולה המחשבת שכיחויות עבור כל חלק\n",
    "# for file in split_arr:\n",
    "#     filename = f\"{file}\"\n",
    "#     ext = '.csv'\n",
    "#     name, ext = os.path.splitext(filename)\n",
    "#     count_errors_in_chunk(file, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_Code</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERR_400</td>\n",
       "      <td>20036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERR_500</td>\n",
       "      <td>20202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFO_200</td>\n",
       "      <td>19782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WARN_101</td>\n",
       "      <td>19980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ERR_404</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Error_Code  Count\n",
       "0    ERR_400  20036\n",
       "1    ERR_500  20202\n",
       "2   INFO_200  19782\n",
       "3   WARN_101  19980\n",
       "4    ERR_404  20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#הדפסה כדי לראות את כל התוכן של הקובץ עם השכיחויות עבור חלק מסויים\n",
    "df=pd.read_csv(\"split10_with_freq.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['split10_with_freq.csv',\n",
       " 'split1_with_freq.csv',\n",
       " 'split2_with_freq.csv',\n",
       " 'split3_with_freq.csv',\n",
       " 'split4_with_freq.csv',\n",
       " 'split5_with_freq.csv',\n",
       " 'split6_with_freq.csv',\n",
       " 'split7_with_freq.csv',\n",
       " 'split8_with_freq.csv',\n",
       " 'split9_with_freq.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#הכנסה למערך את כל המצביעים לקבצים המחולקים\n",
    "errors_csv_arr = glob.glob(\"split*_with_freq.csv\") \n",
    "errors_csv_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERR_400</th>\n",
       "      <th>ERR_500</th>\n",
       "      <th>WARN_101</th>\n",
       "      <th>ERR_404</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ERR_400, ERR_500, WARN_101, ERR_404]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = ['ERR_400', 'ERR_500', 'WARN_101', 'ERR_404']\n",
    "new_df = pd.DataFrame(columns=errors)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ERR_400</th>\n",
       "      <th>ERR_500</th>\n",
       "      <th>WARN_101</th>\n",
       "      <th>ERR_404</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200078</td>\n",
       "      <td>199808</td>\n",
       "      <td>200098</td>\n",
       "      <td>200094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ERR_400  ERR_500  WARN_101  ERR_404\n",
       "0   200078   199808    200098   200094"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_file_of_error_with_freq(arr_of_error_files, dest_file):\n",
    "    if dest_file.empty:\n",
    "        dest_file = pd.DataFrame([[0] * len(dest_file.columns)], columns=dest_file.columns)\n",
    "    for file_name in arr_of_error_files:\n",
    "        try:\n",
    "            with open(file_name, 'r', newline='', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    error_code = line.split(',')[0]\n",
    "                    count = line.split(',')[1]\n",
    "                    if error_code in dest_file.columns:\n",
    "                        dest_file.loc[0,error_code] += int(count)\n",
    "                    \n",
    "        except FileNotFoundError:\n",
    "            print(f\"שגיאה: הקובץ {file_name} לא נמצא.\")\n",
    "        except OSError as e:\n",
    "            print(f\"שגיאת מערכת בקובץ {file_name}: {e}\")\n",
    "    return dest_file\n",
    "\n",
    "\n",
    "# updated_df = build_file_of_error_with_freq(errors_csv_arr, new_df)\n",
    "\n",
    "# updated_df.to_csv(\"all_errors_with_frequency.csv\", index=False, encoding='utf-8')\n",
    "# df= pd.read_csv(\"all_errors_with_frequency.csv\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('WARN_101', 200098), ('ERR_404', 200094)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_error_counter = Counter()\n",
    "errors = df.iloc[0].to_dict()\n",
    "errors\n",
    "all_error_counter = Counter(errors)\n",
    "all_error_counter.most_common(2)\n",
    "# for error in updated_df.columns():\n",
    "#     cnt[error] += updated_df.loc[0, error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3 most common errors:  [('WARN_101', 200098), ('ERR_404', 200094), ('ERR_400', 200078)]\n"
     ]
    }
   ],
   "source": [
    "#פונקציה ראשית הנעזרת בכל הפונקציות שלעיל\n",
    "#מקבלת כקלט קובץ טקסט גדול ומחזירה רשימה של N קודי השגיאה השכיחים ביותר\n",
    "\n",
    "def N_freq_error(file, N):\n",
    "    \n",
    "    if(N > 4):\n",
    "        print(\"N need to be between 0-4\")\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        #זימון הפונ' הממירה את הקובץ הגדול ל CSV\n",
    "        convert_excel_to_csv(file, \"logs.csv\")\n",
    "\n",
    "        #זימון הפונ' המחלקת את הקובץ הגדול\n",
    "        split_csv_data(\"logs.csv\", 100000, \"split\")\n",
    "\n",
    "        #הכנסת כל המצביעים של הקבצים הקטנים לתוך מערך\n",
    "        split_arr = glob.glob(\"split*.csv\") \n",
    "\n",
    "        #זימון הפעולה המחשבת שכיחויות עבור כל חלק\n",
    "        for file in split_arr:\n",
    "            filename = f\"{file}\"\n",
    "            ext = '.csv'\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            count_errors_in_chunk(file, name)\n",
    "\n",
    "        #הכנסה למערך את כל המצביעים לקבצים המחולקים עם השכיחויות\n",
    "        errors_csv_arr = glob.glob(\"split*_with_freq.csv\") \n",
    "\n",
    "        errors = ['ERR_400', 'ERR_500', 'WARN_101', 'ERR_404']\n",
    "        new_df = pd.DataFrame(columns=errors)\n",
    "\n",
    "        updated_df = build_file_of_error_with_freq(errors_csv_arr, new_df)\n",
    "\n",
    "        updated_df.to_csv(\"all_errors_with_frequency.csv\", index=False, encoding='utf-8')\n",
    "        df= pd.read_csv(\"all_errors_with_frequency.csv\")\n",
    "\n",
    "\n",
    "        all_error_counter = Counter()\n",
    "        errors = df.iloc[0].to_dict()\n",
    "        all_error_counter = Counter(errors)\n",
    "        return all_error_counter.most_common(N)\n",
    "\n",
    "N = 3\n",
    "print(f\"The {N} most common errors: \", N_freq_error(\"logs.txt.xlsx\", N))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ניתוח סיבוכיות זמן ריצה וסיבוכיות זיכרון:\n",
    "\n",
    "זמן ריצה-\n",
    "\n",
    "כמות השורות בקובץ שהתקבל כפלט - n\n",
    "\n",
    "כמות הקבצים שנוצרו מחילוק הקובץ הגדול - m (n/100000)\n",
    "\n",
    "חישוב הסיבוכיות:\n",
    "\n",
    "המרת הקובץ לCSV O(n) - עוברים על כל שורה.\n",
    "\n",
    "חלוקת הקובץ O(n) - עוברים על כל שורה.\n",
    "\n",
    "ניתוח קוד השגיאה O(n) - עוברים על כל החלקים ובכל אחד עוברים על כל השורות, סה\"כ n שורות.\n",
    "\n",
    "מיזוג כל הקבצים O(m) - כמות השגיאות היה קבועה ולכן לא נחשבת.\n",
    "\n",
    "בניית Counter O(1) - Counter עובד על Hash Table.\n",
    "\n",
    "סה\"כ סיבוכיות זיכרון - O(n)\n",
    "\n",
    "זיכרון:\n",
    "\n",
    "הזיכרון קבוע O(1)\n",
    "\n",
    "בגלל שהפונקציות משתמשות ב chunksize\n",
    "\n",
    "אף פעם לא כל השורות יטענו לזיכרון. המקסימום שיהיה בזיכרון הוא 100000 שורות."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
